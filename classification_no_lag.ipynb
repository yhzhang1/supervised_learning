{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import huber_loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety = 'RB'\n",
    "\n",
    "factor_store = pd.HDFStore('/home/data/vb/training_x_150.h5', mode='r')\n",
    "factor_df = factor_store.get(variety)\n",
    "y_store = pd.HDFStore('/home/data/vb/training_y_reg_150.h5', mode='r')\n",
    "y_series = y_store.get(variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9440944278>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret_y_series = np.exp(y_series) - 1 # 获得回报的原始收益\n",
    "ret_y_series.hist(range=(-1,1), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    99419.000000\n",
       "mean         0.116054\n",
       "std          3.241139\n",
       "min         -0.999923\n",
       "25%         -0.183089\n",
       "50%          0.000000\n",
       "75%          0.229571\n",
       "max        355.517368\n",
       "Name: Y_logret, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_y_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08375886505374186"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_y_series.quantile(q=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给ret分类\n",
    "def label_ret(ret):\n",
    "    '''\n",
    "    class 0 = [-inf, -0.1]\n",
    "    class 1 = [-0.1, 0.1] unprofitable\n",
    "    class 2 = [0.1, inf]\n",
    "    '''\n",
    "    label = None\n",
    "    if ret < -0.1:\n",
    "        label = 0\n",
    "    elif -0.1 <= ret and ret <= 0.1:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 2\n",
    "        \n",
    "    return label\n",
    "        \n",
    "def label_ret_bi(ret):\n",
    "    label = None\n",
    "    if ret <= 0:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    return label        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_time\n",
       "2015-04-29 13:45:42.500    0\n",
       "2015-04-29 13:46:23.500    0\n",
       "2015-04-29 13:47:33.000    0\n",
       "2015-04-29 13:48:47.500    0\n",
       "2015-04-29 13:51:33.500    0\n",
       "Name: Y_label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_y_series = ret_y_series.transform(label_ret_bi).rename('Y_label')\n",
    "label_y_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_logret</th>\n",
       "      <th>Y_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-29 13:45:42.500</th>\n",
       "      <td>-0.041189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-29 13:46:23.500</th>\n",
       "      <td>-0.189663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-29 13:47:33.000</th>\n",
       "      <td>-0.154882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-29 13:48:47.500</th>\n",
       "      <td>-0.223081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-29 13:51:33.500</th>\n",
       "      <td>-0.189806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Y_logret  Y_label\n",
       "start_time                                \n",
       "2015-04-29 13:45:42.500 -0.041189        0\n",
       "2015-04-29 13:46:23.500 -0.189663        0\n",
       "2015-04-29 13:47:33.000 -0.154882        0\n",
       "2015-04-29 13:48:47.500 -0.223081        0\n",
       "2015-04-29 13:51:33.500 -0.189806        0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_label_df = pd.concat([ret_y_series, label_y_series], axis=1)\n",
    "ret_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = factor_df.join(label_y_series)\n",
    "df = df.dropna()\n",
    "factor_df = df[factor_df.columns]\n",
    "label_y_series = df[label_y_series.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(factor_df.index == label_y_series.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_train, factor_test, y_train, y_test = train_test_split(factor_df, label_y_series, test_size=0.25, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "y_train_cat = keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gpu_option():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.Session(config=config)\n",
    "    keras.backend.tensorflow_backend.set_session(sess)\n",
    "    \n",
    "def create_model(in_shape, num_classes):\n",
    "    NUM_NEURONS = 16\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NUM_NEURONS, input_shape=input_shape, activation='relu'))\n",
    "    model.add(Dense(NUM_NEURONS, activation='relu'))\n",
    "    model.add(Dense(NUM_NEURONS, activation='relu'))\n",
    "    model.add(Dense(NUM_NEURONS, activation='relu'))\n",
    "\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))  \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_time\n",
       "2015-04-29 13:45:42.500    0\n",
       "2015-04-29 13:46:23.500    0\n",
       "2015-04-29 13:47:33.000    0\n",
       "2015-04-29 13:48:47.500    0\n",
       "2015-04-29 13:51:33.500    0\n",
       "                          ..\n",
       "2017-06-26 09:11:43.500    1\n",
       "2017-06-26 09:13:58.500    1\n",
       "2017-06-26 09:16:09.500    1\n",
       "2017-06-26 09:17:43.500    1\n",
       "2017-06-26 09:21:28.000    1\n",
       "Name: Y_label, Length: 74564, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def Precision(y_true, y_pred):\n",
    "    \"\"\"精确率\"\"\"\n",
    "    tp= K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # true positives\n",
    "    pp= K.sum(K.round(K.clip(y_pred, 0, 1))) # predicted positives\n",
    "    precision = tp/ (pp+ K.epsilon())\n",
    "    return precision\n",
    "    \n",
    "def Recall(y_true, y_pred):\n",
    "    \"\"\"召回率\"\"\"\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # true positives\n",
    "    pp = K.sum(K.round(K.clip(y_true, 0, 1))) # possible positives\n",
    "    recall = tp / (pp + K.epsilon())\n",
    "    return recall\n",
    " \n",
    "def F1(y_true, y_pred):\n",
    "    \"\"\"F1-score\"\"\"\n",
    "    precision = Precision(y_true, y_pred)\n",
    "    recall = Recall(y_true, y_pred)\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    return f1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 16)                2832      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 3,682\n",
      "Trainable params: 3,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (factor_df.shape[1],)\n",
    "NUM_CLASSES = 2\n",
    "model = create_model(in_shape=input_shape, num_classes=NUM_CLASSES)\n",
    "set_gpu_option()\n",
    "model.compile(optimizer=Adam(lr=1e-6),loss='categorical_crossentropy', metrics=['accuracy', Precision, Recall, F1])\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67095 samples, validate on 7456 samples\n",
      "Epoch 1/100\n",
      "67095/67095 [==============================] - 11s 161us/step - loss: 23.9310 - accuracy: 0.4876 - Precision: 0.4876 - Recall: 0.4876 - F1: 0.4876 - val_loss: 17.9568 - val_accuracy: 0.5058 - val_Precision: 0.5058 - val_Recall: 0.5058 - val_F1: 0.5058\n",
      "Epoch 2/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 20.3078 - accuracy: 0.4891 - Precision: 0.4890 - Recall: 0.4890 - F1: 0.4890 - val_loss: 13.7089 - val_accuracy: 0.5004 - val_Precision: 0.5004 - val_Recall: 0.5004 - val_F1: 0.5004\n",
      "Epoch 3/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 17.0994 - accuracy: 0.4887 - Precision: 0.4887 - Recall: 0.4887 - F1: 0.4887 - val_loss: 9.8438 - val_accuracy: 0.5031 - val_Precision: 0.5031 - val_Recall: 0.5031 - val_F1: 0.5031\n",
      "Epoch 4/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 14.6171 - accuracy: 0.4917 - Precision: 0.4917 - Recall: 0.4917 - F1: 0.4917 - val_loss: 7.2389 - val_accuracy: 0.5007 - val_Precision: 0.5007 - val_Recall: 0.5007 - val_F1: 0.5007\n",
      "Epoch 5/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 13.3081 - accuracy: 0.4934 - Precision: 0.4934 - Recall: 0.4934 - F1: 0.4934 - val_loss: 6.2928 - val_accuracy: 0.5039 - val_Precision: 0.5039 - val_Recall: 0.5039 - val_F1: 0.5039\n",
      "Epoch 6/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 12.8002 - accuracy: 0.4947 - Precision: 0.4947 - Recall: 0.4947 - F1: 0.4947 - val_loss: 5.9747 - val_accuracy: 0.5021 - val_Precision: 0.5021 - val_Recall: 0.5021 - val_F1: 0.5021\n",
      "Epoch 7/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 12.4489 - accuracy: 0.4958 - Precision: 0.4958 - Recall: 0.4958 - F1: 0.4958 - val_loss: 5.7591 - val_accuracy: 0.5024 - val_Precision: 0.5024 - val_Recall: 0.5024 - val_F1: 0.5024\n",
      "Epoch 8/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 12.1301 - accuracy: 0.4961 - Precision: 0.4961 - Recall: 0.4961 - F1: 0.4961 - val_loss: 5.5865 - val_accuracy: 0.5005 - val_Precision: 0.5005 - val_Recall: 0.5005 - val_F1: 0.5005\n",
      "Epoch 9/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 11.8339 - accuracy: 0.4969 - Precision: 0.4969 - Recall: 0.4969 - F1: 0.4969 - val_loss: 5.4368 - val_accuracy: 0.4987 - val_Precision: 0.4987 - val_Recall: 0.4987 - val_F1: 0.4987\n",
      "Epoch 10/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 11.5570 - accuracy: 0.4974 - Precision: 0.4974 - Recall: 0.4974 - F1: 0.4974 - val_loss: 5.3015 - val_accuracy: 0.4980 - val_Precision: 0.4980 - val_Recall: 0.4980 - val_F1: 0.4980\n",
      "Epoch 11/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 11.2961 - accuracy: 0.4981 - Precision: 0.4981 - Recall: 0.4981 - F1: 0.4981 - val_loss: 5.1763 - val_accuracy: 0.4993 - val_Precision: 0.4993 - val_Recall: 0.4993 - val_F1: 0.4993\n",
      "Epoch 12/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 11.0477 - accuracy: 0.4980 - Precision: 0.4980 - Recall: 0.4980 - F1: 0.4980 - val_loss: 5.0558 - val_accuracy: 0.4984 - val_Precision: 0.4984 - val_Recall: 0.4984 - val_F1: 0.4984\n",
      "Epoch 13/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 10.8107 - accuracy: 0.4988 - Precision: 0.4988 - Recall: 0.4988 - F1: 0.4988 - val_loss: 4.9423 - val_accuracy: 0.4991 - val_Precision: 0.4991 - val_Recall: 0.4991 - val_F1: 0.4991\n",
      "Epoch 14/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 10.5832 - accuracy: 0.4988 - Precision: 0.4988 - Recall: 0.4988 - F1: 0.4988 - val_loss: 4.8350 - val_accuracy: 0.4997 - val_Precision: 0.4997 - val_Recall: 0.4997 - val_F1: 0.4997\n",
      "Epoch 15/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 10.3667 - accuracy: 0.4986 - Precision: 0.4986 - Recall: 0.4986 - F1: 0.4986 - val_loss: 4.7366 - val_accuracy: 0.4991 - val_Precision: 0.4991 - val_Recall: 0.4991 - val_F1: 0.4991\n",
      "Epoch 16/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 10.1608 - accuracy: 0.4992 - Precision: 0.4992 - Recall: 0.4992 - F1: 0.4992 - val_loss: 4.6454 - val_accuracy: 0.5000 - val_Precision: 0.5000 - val_Recall: 0.5000 - val_F1: 0.5000\n",
      "Epoch 17/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 9.9646 - accuracy: 0.4994 - Precision: 0.4994 - Recall: 0.4994 - F1: 0.4994 - val_loss: 4.5589 - val_accuracy: 0.4999 - val_Precision: 0.4999 - val_Recall: 0.4999 - val_F1: 0.4999\n",
      "Epoch 18/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 9.7754 - accuracy: 0.4998 - Precision: 0.4998 - Recall: 0.4998 - F1: 0.4998 - val_loss: 4.4748 - val_accuracy: 0.4984 - val_Precision: 0.4984 - val_Recall: 0.4984 - val_F1: 0.4984\n",
      "Epoch 19/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 9.5919 - accuracy: 0.5002 - Precision: 0.5002 - Recall: 0.5002 - F1: 0.5002 - val_loss: 4.3952 - val_accuracy: 0.4987 - val_Precision: 0.4987 - val_Recall: 0.4987 - val_F1: 0.4987\n",
      "Epoch 20/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 9.4134 - accuracy: 0.5005 - Precision: 0.5006 - Recall: 0.5006 - F1: 0.5006 - val_loss: 4.3179 - val_accuracy: 0.4979 - val_Precision: 0.4979 - val_Recall: 0.4979 - val_F1: 0.4979\n",
      "Epoch 21/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 9.2401 - accuracy: 0.5003 - Precision: 0.5003 - Recall: 0.5003 - F1: 0.5003 - val_loss: 4.2439 - val_accuracy: 0.4975 - val_Precision: 0.4975 - val_Recall: 0.4975 - val_F1: 0.4975\n",
      "Epoch 22/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 9.0709 - accuracy: 0.5007 - Precision: 0.5007 - Recall: 0.5007 - F1: 0.5007 - val_loss: 4.1725 - val_accuracy: 0.4987 - val_Precision: 0.4987 - val_Recall: 0.4987 - val_F1: 0.4987\n",
      "Epoch 23/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 8.9049 - accuracy: 0.5009 - Precision: 0.5009 - Recall: 0.5009 - F1: 0.5009 - val_loss: 4.1025 - val_accuracy: 0.4996 - val_Precision: 0.4996 - val_Recall: 0.4996 - val_F1: 0.4996\n",
      "Epoch 24/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 8.7433 - accuracy: 0.5012 - Precision: 0.5012 - Recall: 0.5012 - F1: 0.5012 - val_loss: 4.0338 - val_accuracy: 0.4989 - val_Precision: 0.4989 - val_Recall: 0.4989 - val_F1: 0.4989\n",
      "Epoch 25/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 8.5843 - accuracy: 0.5012 - Precision: 0.5012 - Recall: 0.5012 - F1: 0.5012 - val_loss: 3.9679 - val_accuracy: 0.5000 - val_Precision: 0.5000 - val_Recall: 0.5000 - val_F1: 0.5000\n",
      "Epoch 26/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 8.4292 - accuracy: 0.5011 - Precision: 0.5011 - Recall: 0.5011 - F1: 0.5011 - val_loss: 3.9039 - val_accuracy: 0.4985 - val_Precision: 0.4985 - val_Recall: 0.4985 - val_F1: 0.4985\n",
      "Epoch 27/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 8.2776 - accuracy: 0.5016 - Precision: 0.5016 - Recall: 0.5016 - F1: 0.5016 - val_loss: 3.8424 - val_accuracy: 0.5007 - val_Precision: 0.5007 - val_Recall: 0.5007 - val_F1: 0.5007\n",
      "Epoch 28/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 8.1290 - accuracy: 0.5012 - Precision: 0.5013 - Recall: 0.5013 - F1: 0.5013 - val_loss: 3.7833 - val_accuracy: 0.5009 - val_Precision: 0.5009 - val_Recall: 0.5009 - val_F1: 0.5009\n",
      "Epoch 29/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 7.9829 - accuracy: 0.5012 - Precision: 0.5012 - Recall: 0.5012 - F1: 0.5012 - val_loss: 3.7261 - val_accuracy: 0.5004 - val_Precision: 0.5004 - val_Recall: 0.5004 - val_F1: 0.5004\n",
      "Epoch 30/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 7.8389 - accuracy: 0.5012 - Precision: 0.5012 - Recall: 0.5012 - F1: 0.5012 - val_loss: 3.6704 - val_accuracy: 0.5016 - val_Precision: 0.5016 - val_Recall: 0.5016 - val_F1: 0.5016\n",
      "Epoch 31/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 7.6975 - accuracy: 0.5009 - Precision: 0.5009 - Recall: 0.5009 - F1: 0.5009 - val_loss: 3.6163 - val_accuracy: 0.5013 - val_Precision: 0.5013 - val_Recall: 0.5013 - val_F1: 0.5013\n",
      "Epoch 32/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 7.5592 - accuracy: 0.5011 - Precision: 0.5011 - Recall: 0.5011 - F1: 0.5011 - val_loss: 3.5639 - val_accuracy: 0.5013 - val_Precision: 0.5013 - val_Recall: 0.5013 - val_F1: 0.5013\n",
      "Epoch 33/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 7.4239 - accuracy: 0.5008 - Precision: 0.5009 - Recall: 0.5009 - F1: 0.5009 - val_loss: 3.5124 - val_accuracy: 0.5007 - val_Precision: 0.5007 - val_Recall: 0.5007 - val_F1: 0.5007\n",
      "Epoch 34/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 7.2918 - accuracy: 0.5010 - Precision: 0.5010 - Recall: 0.5010 - F1: 0.5010 - val_loss: 3.4625 - val_accuracy: 0.5019 - val_Precision: 0.5019 - val_Recall: 0.5019 - val_F1: 0.5019\n",
      "Epoch 35/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 7.1619 - accuracy: 0.5011 - Precision: 0.5011 - Recall: 0.5011 - F1: 0.5011 - val_loss: 3.4137 - val_accuracy: 0.5007 - val_Precision: 0.5007 - val_Recall: 0.5007 - val_F1: 0.5007\n",
      "Epoch 36/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 7.0342 - accuracy: 0.5008 - Precision: 0.5008 - Recall: 0.5008 - F1: 0.5008 - val_loss: 3.3661 - val_accuracy: 0.5011 - val_Precision: 0.5011 - val_Recall: 0.5011 - val_F1: 0.5011\n",
      "Epoch 37/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 6.9089 - accuracy: 0.5009 - Precision: 0.5009 - Recall: 0.5009 - F1: 0.5009 - val_loss: 3.3198 - val_accuracy: 0.4983 - val_Precision: 0.4983 - val_Recall: 0.4983 - val_F1: 0.4983\n",
      "Epoch 38/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 6.7858 - accuracy: 0.5012 - Precision: 0.5012 - Recall: 0.5012 - F1: 0.5012 - val_loss: 3.2746 - val_accuracy: 0.4988 - val_Precision: 0.4988 - val_Recall: 0.4988 - val_F1: 0.4988\n",
      "Epoch 39/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 6.6645 - accuracy: 0.5014 - Precision: 0.5014 - Recall: 0.5014 - F1: 0.5014 - val_loss: 3.2306 - val_accuracy: 0.5001 - val_Precision: 0.5001 - val_Recall: 0.5001 - val_F1: 0.5001\n",
      "Epoch 40/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 6.5456 - accuracy: 0.5014 - Precision: 0.5014 - Recall: 0.5014 - F1: 0.5014 - val_loss: 3.1870 - val_accuracy: 0.4995 - val_Precision: 0.4995 - val_Recall: 0.4995 - val_F1: 0.4995\n",
      "Epoch 41/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 6.4294 - accuracy: 0.5013 - Precision: 0.5013 - Recall: 0.5013 - F1: 0.5013 - val_loss: 3.1442 - val_accuracy: 0.4996 - val_Precision: 0.4996 - val_Recall: 0.4996 - val_F1: 0.4996\n",
      "Epoch 42/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 6.3145 - accuracy: 0.5014 - Precision: 0.5014 - Recall: 0.5014 - F1: 0.5014 - val_loss: 3.1026 - val_accuracy: 0.5001 - val_Precision: 0.5001 - val_Recall: 0.5001 - val_F1: 0.5001\n",
      "Epoch 43/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 6.2014 - accuracy: 0.5015 - Precision: 0.5015 - Recall: 0.5015 - F1: 0.5015 - val_loss: 3.0620 - val_accuracy: 0.5013 - val_Precision: 0.5013 - val_Recall: 0.5013 - val_F1: 0.5013\n",
      "Epoch 44/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 6.0919 - accuracy: 0.5018 - Precision: 0.5018 - Recall: 0.5018 - F1: 0.5018 - val_loss: 3.0223 - val_accuracy: 0.5009 - val_Precision: 0.5009 - val_Recall: 0.5009 - val_F1: 0.5009\n",
      "Epoch 45/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 5.9844 - accuracy: 0.5019 - Precision: 0.5019 - Recall: 0.5019 - F1: 0.5019 - val_loss: 2.9841 - val_accuracy: 0.5000 - val_Precision: 0.5000 - val_Recall: 0.5000 - val_F1: 0.5000\n",
      "Epoch 46/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 5.8787 - accuracy: 0.5018 - Precision: 0.5018 - Recall: 0.5018 - F1: 0.5018 - val_loss: 2.9469 - val_accuracy: 0.4997 - val_Precision: 0.4997 - val_Recall: 0.4997 - val_F1: 0.4997\n",
      "Epoch 47/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 5.7752 - accuracy: 0.5023 - Precision: 0.5023 - Recall: 0.5023 - F1: 0.5023 - val_loss: 2.9109 - val_accuracy: 0.4996 - val_Precision: 0.4996 - val_Recall: 0.4996 - val_F1: 0.4996\n",
      "Epoch 48/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 5.6733 - accuracy: 0.5026 - Precision: 0.5026 - Recall: 0.5026 - F1: 0.5026 - val_loss: 2.8759 - val_accuracy: 0.4991 - val_Precision: 0.4991 - val_Recall: 0.4991 - val_F1: 0.4991\n",
      "Epoch 49/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 5.5738 - accuracy: 0.5026 - Precision: 0.5026 - Recall: 0.5026 - F1: 0.5026 - val_loss: 2.8419 - val_accuracy: 0.4983 - val_Precision: 0.4983 - val_Recall: 0.4983 - val_F1: 0.4983\n",
      "Epoch 50/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 5.4762 - accuracy: 0.5027 - Precision: 0.5027 - Recall: 0.5027 - F1: 0.5027 - val_loss: 2.8083 - val_accuracy: 0.4995 - val_Precision: 0.4995 - val_Recall: 0.4995 - val_F1: 0.4995\n",
      "Epoch 51/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 5.3801 - accuracy: 0.5028 - Precision: 0.5028 - Recall: 0.5028 - F1: 0.5028 - val_loss: 2.7755 - val_accuracy: 0.4997 - val_Precision: 0.4997 - val_Recall: 0.4997 - val_F1: 0.4997\n",
      "Epoch 52/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 5.2854 - accuracy: 0.5027 - Precision: 0.5027 - Recall: 0.5027 - F1: 0.5027 - val_loss: 2.7433 - val_accuracy: 0.4992 - val_Precision: 0.4992 - val_Recall: 0.4992 - val_F1: 0.4992\n",
      "Epoch 53/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 5.1931 - accuracy: 0.5028 - Precision: 0.5028 - Recall: 0.5028 - F1: 0.5028 - val_loss: 2.7117 - val_accuracy: 0.4991 - val_Precision: 0.4991 - val_Recall: 0.4991 - val_F1: 0.4991\n",
      "Epoch 54/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 5.1076 - accuracy: 0.5030 - Precision: 0.5031 - Recall: 0.5031 - F1: 0.5031 - val_loss: 2.6818 - val_accuracy: 0.4995 - val_Precision: 0.4995 - val_Recall: 0.4995 - val_F1: 0.4995\n",
      "Epoch 55/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 5.0243 - accuracy: 0.5034 - Precision: 0.5034 - Recall: 0.5034 - F1: 0.5034 - val_loss: 2.6529 - val_accuracy: 0.4996 - val_Precision: 0.4996 - val_Recall: 0.4996 - val_F1: 0.4996\n",
      "Epoch 56/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 4.9424 - accuracy: 0.5028 - Precision: 0.5028 - Recall: 0.5028 - F1: 0.5028 - val_loss: 2.6254 - val_accuracy: 0.5005 - val_Precision: 0.5005 - val_Recall: 0.5005 - val_F1: 0.5005\n",
      "Epoch 57/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 4.8637 - accuracy: 0.5026 - Precision: 0.5026 - Recall: 0.5026 - F1: 0.5026 - val_loss: 2.5989 - val_accuracy: 0.5000 - val_Precision: 0.5000 - val_Recall: 0.5000 - val_F1: 0.5000\n",
      "Epoch 58/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 4.7870 - accuracy: 0.5020 - Precision: 0.5020 - Recall: 0.5020 - F1: 0.5020 - val_loss: 2.5734 - val_accuracy: 0.5004 - val_Precision: 0.5004 - val_Recall: 0.5004 - val_F1: 0.5004\n",
      "Epoch 59/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 4.7122 - accuracy: 0.5023 - Precision: 0.5023 - Recall: 0.5023 - F1: 0.5023 - val_loss: 2.5492 - val_accuracy: 0.4992 - val_Precision: 0.4992 - val_Recall: 0.4992 - val_F1: 0.4992\n",
      "Epoch 60/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 4.6413 - accuracy: 0.5022 - Precision: 0.5022 - Recall: 0.5022 - F1: 0.5022 - val_loss: 2.5262 - val_accuracy: 0.4980 - val_Precision: 0.4980 - val_Recall: 0.4980 - val_F1: 0.4980\n",
      "Epoch 61/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 4.5726 - accuracy: 0.5015 - Precision: 0.5015 - Recall: 0.5015 - F1: 0.5015 - val_loss: 2.5043 - val_accuracy: 0.4988 - val_Precision: 0.4988 - val_Recall: 0.4988 - val_F1: 0.4988\n",
      "Epoch 62/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 4.5046 - accuracy: 0.5016 - Precision: 0.5016 - Recall: 0.5016 - F1: 0.5016 - val_loss: 2.4833 - val_accuracy: 0.4993 - val_Precision: 0.4993 - val_Recall: 0.4993 - val_F1: 0.4993\n",
      "Epoch 63/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 4.4374 - accuracy: 0.5012 - Precision: 0.5012 - Recall: 0.5012 - F1: 0.5012 - val_loss: 2.4630 - val_accuracy: 0.4993 - val_Precision: 0.4993 - val_Recall: 0.4993 - val_F1: 0.4993\n",
      "Epoch 64/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 4.3707 - accuracy: 0.5011 - Precision: 0.5011 - Recall: 0.5011 - F1: 0.5011 - val_loss: 2.4434 - val_accuracy: 0.4999 - val_Precision: 0.4999 - val_Recall: 0.4999 - val_F1: 0.4999\n",
      "Epoch 65/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 4.3046 - accuracy: 0.5013 - Precision: 0.5013 - Recall: 0.5013 - F1: 0.5013 - val_loss: 2.4243 - val_accuracy: 0.5005 - val_Precision: 0.5005 - val_Recall: 0.5005 - val_F1: 0.5005\n",
      "Epoch 66/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 4.2391 - accuracy: 0.5011 - Precision: 0.5011 - Recall: 0.5011 - F1: 0.5011 - val_loss: 2.4057 - val_accuracy: 0.5000 - val_Precision: 0.5000 - val_Recall: 0.5000 - val_F1: 0.5000\n",
      "Epoch 67/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 4.1737 - accuracy: 0.5006 - Precision: 0.5006 - Recall: 0.5006 - F1: 0.5006 - val_loss: 2.3878 - val_accuracy: 0.4989 - val_Precision: 0.4989 - val_Recall: 0.4989 - val_F1: 0.4989\n",
      "Epoch 68/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 4.1088 - accuracy: 0.5004 - Precision: 0.5004 - Recall: 0.5004 - F1: 0.5004 - val_loss: 2.3703 - val_accuracy: 0.4988 - val_Precision: 0.4988 - val_Recall: 0.4988 - val_F1: 0.4988\n",
      "Epoch 69/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 4.0446 - accuracy: 0.5002 - Precision: 0.5002 - Recall: 0.5002 - F1: 0.5002 - val_loss: 2.3534 - val_accuracy: 0.4987 - val_Precision: 0.4987 - val_Recall: 0.4987 - val_F1: 0.4987\n",
      "Epoch 70/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.9813 - accuracy: 0.5001 - Precision: 0.5001 - Recall: 0.5001 - F1: 0.5001 - val_loss: 2.3369 - val_accuracy: 0.4979 - val_Precision: 0.4979 - val_Recall: 0.4979 - val_F1: 0.4979\n",
      "Epoch 71/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 3.9188 - accuracy: 0.5000 - Precision: 0.5001 - Recall: 0.5001 - F1: 0.5001 - val_loss: 2.3208 - val_accuracy: 0.4969 - val_Precision: 0.4969 - val_Recall: 0.4969 - val_F1: 0.4969\n",
      "Epoch 72/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.8569 - accuracy: 0.4999 - Precision: 0.5000 - Recall: 0.5000 - F1: 0.5000 - val_loss: 2.3052 - val_accuracy: 0.4970 - val_Precision: 0.4970 - val_Recall: 0.4970 - val_F1: 0.4970\n",
      "Epoch 73/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.7957 - accuracy: 0.5001 - Precision: 0.5002 - Recall: 0.5002 - F1: 0.5002 - val_loss: 2.2898 - val_accuracy: 0.4976 - val_Precision: 0.4976 - val_Recall: 0.4976 - val_F1: 0.4976\n",
      "Epoch 74/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 3.7351 - accuracy: 0.5002 - Precision: 0.5002 - Recall: 0.5002 - F1: 0.5002 - val_loss: 2.2747 - val_accuracy: 0.4975 - val_Precision: 0.4975 - val_Recall: 0.4975 - val_F1: 0.4975\n",
      "Epoch 75/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.6751 - accuracy: 0.5001 - Precision: 0.5001 - Recall: 0.5001 - F1: 0.5001 - val_loss: 2.2598 - val_accuracy: 0.4969 - val_Precision: 0.4969 - val_Recall: 0.4969 - val_F1: 0.4969\n",
      "Epoch 76/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.6160 - accuracy: 0.5001 - Precision: 0.5001 - Recall: 0.5001 - F1: 0.5001 - val_loss: 2.2453 - val_accuracy: 0.4969 - val_Precision: 0.4969 - val_Recall: 0.4969 - val_F1: 0.4969\n",
      "Epoch 77/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.5578 - accuracy: 0.5000 - Precision: 0.5000 - Recall: 0.5000 - F1: 0.5000 - val_loss: 2.2312 - val_accuracy: 0.4977 - val_Precision: 0.4977 - val_Recall: 0.4977 - val_F1: 0.4977\n",
      "Epoch 78/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 3.5009 - accuracy: 0.4998 - Precision: 0.4998 - Recall: 0.4998 - F1: 0.4998 - val_loss: 2.2173 - val_accuracy: 0.4983 - val_Precision: 0.4983 - val_Recall: 0.4983 - val_F1: 0.4983\n",
      "Epoch 79/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 3.4455 - accuracy: 0.4998 - Precision: 0.4998 - Recall: 0.4998 - F1: 0.4998 - val_loss: 2.2037 - val_accuracy: 0.4985 - val_Precision: 0.4985 - val_Recall: 0.4985 - val_F1: 0.4985\n",
      "Epoch 80/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.3910 - accuracy: 0.5001 - Precision: 0.5001 - Recall: 0.5001 - F1: 0.5001 - val_loss: 2.1904 - val_accuracy: 0.4992 - val_Precision: 0.4992 - val_Recall: 0.4992 - val_F1: 0.4992\n",
      "Epoch 81/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.3373 - accuracy: 0.4995 - Precision: 0.4995 - Recall: 0.4995 - F1: 0.4995 - val_loss: 2.1774 - val_accuracy: 0.4984 - val_Precision: 0.4984 - val_Recall: 0.4984 - val_F1: 0.4984\n",
      "Epoch 82/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.2852 - accuracy: 0.4996 - Precision: 0.4997 - Recall: 0.4997 - F1: 0.4997 - val_loss: 2.1647 - val_accuracy: 0.4983 - val_Precision: 0.4983 - val_Recall: 0.4983 - val_F1: 0.4983\n",
      "Epoch 83/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.2356 - accuracy: 0.4996 - Precision: 0.4996 - Recall: 0.4996 - F1: 0.4996 - val_loss: 2.1525 - val_accuracy: 0.4985 - val_Precision: 0.4985 - val_Recall: 0.4985 - val_F1: 0.4985\n",
      "Epoch 84/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.1884 - accuracy: 0.4998 - Precision: 0.4998 - Recall: 0.4998 - F1: 0.4998 - val_loss: 2.1404 - val_accuracy: 0.4984 - val_Precision: 0.4984 - val_Recall: 0.4984 - val_F1: 0.4984\n",
      "Epoch 85/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.1428 - accuracy: 0.4997 - Precision: 0.4998 - Recall: 0.4998 - F1: 0.4998 - val_loss: 2.1286 - val_accuracy: 0.4989 - val_Precision: 0.4989 - val_Recall: 0.4989 - val_F1: 0.4989\n",
      "Epoch 86/100\n",
      "67095/67095 [==============================] - 11s 160us/step - loss: 3.0982 - accuracy: 0.4998 - Precision: 0.4998 - Recall: 0.4998 - F1: 0.4998 - val_loss: 2.1170 - val_accuracy: 0.5000 - val_Precision: 0.5000 - val_Recall: 0.5000 - val_F1: 0.5000\n",
      "Epoch 87/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 3.0557 - accuracy: 0.4996 - Precision: 0.4996 - Recall: 0.4996 - F1: 0.4996 - val_loss: 2.1056 - val_accuracy: 0.5004 - val_Precision: 0.5004 - val_Recall: 0.5004 - val_F1: 0.5004\n",
      "Epoch 88/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 3.0148 - accuracy: 0.4993 - Precision: 0.4993 - Recall: 0.4993 - F1: 0.4993 - val_loss: 2.0946 - val_accuracy: 0.4999 - val_Precision: 0.4999 - val_Recall: 0.4999 - val_F1: 0.4999\n",
      "Epoch 89/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 2.9750 - accuracy: 0.4988 - Precision: 0.4988 - Recall: 0.4988 - F1: 0.4988 - val_loss: 2.0837 - val_accuracy: 0.5000 - val_Precision: 0.5000 - val_Recall: 0.5000 - val_F1: 0.5000\n",
      "Epoch 90/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 2.9362 - accuracy: 0.4990 - Precision: 0.4990 - Recall: 0.4990 - F1: 0.4990 - val_loss: 2.0731 - val_accuracy: 0.5004 - val_Precision: 0.5004 - val_Recall: 0.5004 - val_F1: 0.5004\n",
      "Epoch 91/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 2.8982 - accuracy: 0.4990 - Precision: 0.4990 - Recall: 0.4990 - F1: 0.4990 - val_loss: 2.0627 - val_accuracy: 0.5004 - val_Precision: 0.5004 - val_Recall: 0.5004 - val_F1: 0.5004\n",
      "Epoch 92/100\n",
      "67095/67095 [==============================] - 11s 157us/step - loss: 2.8611 - accuracy: 0.4991 - Precision: 0.4992 - Recall: 0.4992 - F1: 0.4992 - val_loss: 2.0524 - val_accuracy: 0.5001 - val_Precision: 0.5001 - val_Recall: 0.5001 - val_F1: 0.5001\n",
      "Epoch 93/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 2.8245 - accuracy: 0.4994 - Precision: 0.4995 - Recall: 0.4995 - F1: 0.4995 - val_loss: 2.0421 - val_accuracy: 0.5005 - val_Precision: 0.5005 - val_Recall: 0.5005 - val_F1: 0.5005\n",
      "Epoch 94/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 2.7886 - accuracy: 0.4996 - Precision: 0.4997 - Recall: 0.4997 - F1: 0.4997 - val_loss: 2.0320 - val_accuracy: 0.5007 - val_Precision: 0.5007 - val_Recall: 0.5007 - val_F1: 0.5007\n",
      "Epoch 95/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 2.7534 - accuracy: 0.4997 - Precision: 0.4997 - Recall: 0.4997 - F1: 0.4997 - val_loss: 2.0220 - val_accuracy: 0.4987 - val_Precision: 0.4987 - val_Recall: 0.4987 - val_F1: 0.4987\n",
      "Epoch 96/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 2.7192 - accuracy: 0.4998 - Precision: 0.4999 - Recall: 0.4999 - F1: 0.4999 - val_loss: 2.0123 - val_accuracy: 0.4996 - val_Precision: 0.4996 - val_Recall: 0.4996 - val_F1: 0.4996\n",
      "Epoch 97/100\n",
      "67095/67095 [==============================] - 11s 158us/step - loss: 2.6858 - accuracy: 0.5000 - Precision: 0.5000 - Recall: 0.5000 - F1: 0.5000 - val_loss: 2.0026 - val_accuracy: 0.4993 - val_Precision: 0.4993 - val_Recall: 0.4993 - val_F1: 0.4993\n",
      "Epoch 98/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 2.6530 - accuracy: 0.5002 - Precision: 0.5003 - Recall: 0.5003 - F1: 0.5003 - val_loss: 1.9931 - val_accuracy: 0.4995 - val_Precision: 0.4995 - val_Recall: 0.4995 - val_F1: 0.4995\n",
      "Epoch 99/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 2.6210 - accuracy: 0.5007 - Precision: 0.5007 - Recall: 0.5007 - F1: 0.5007 - val_loss: 1.9837 - val_accuracy: 0.4989 - val_Precision: 0.4989 - val_Recall: 0.4989 - val_F1: 0.4989\n",
      "Epoch 100/100\n",
      "67095/67095 [==============================] - 11s 159us/step - loss: 2.5900 - accuracy: 0.5010 - Precision: 0.5011 - Recall: 0.5011 - F1: 0.5011 - val_loss: 1.9743 - val_accuracy: 0.4984 - val_Precision: 0.4984 - val_Recall: 0.4984 - val_F1: 0.4984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f93e90a4940>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=factor_train, y=y_train_cat, epochs=100, verbose=1, validation_split=0.1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24855/24855 [==============================] - 1s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.082537906598191, 0.39372360706329346]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=factor_test, y=y_test_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35685503, 0.27239168, 0.37075332],\n",
       "       [0.35685503, 0.27239168, 0.37075332],\n",
       "       [0.35685503, 0.27239168, 0.37075332],\n",
       "       ...,\n",
       "       [0.35685503, 0.27239168, 0.37075332],\n",
       "       [0.35685503, 0.27239168, 0.37075332],\n",
       "       [0.35685503, 0.27239168, 0.37075332]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_test = model.predict(x=factor_test)\n",
    "predict_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 74565, index implies 24855",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-8a88e83c4bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_y_test_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_y_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict_y_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredict_y_test_series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m'Length of passed values is {val}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                             \u001b[0;34m'index implies {ind}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                             .format(val=len(data), ind=len(index)))\n\u001b[0m\u001b[1;32m    250\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of passed values is 74565, index implies 24855"
     ]
    }
   ],
   "source": [
    "predict_y_test_series = pd.Series(data=predict_y_test.flatten(), index=y_test.index, name='predict_y_test')\n",
    "predict_y_test_series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
